# video-emotion-analyzer
A machine learning model based on convolutional neural networks which successfully predicts the emotions of a person in the video by analyzing his/her facial features
The model was successfully compiled in 4-5 hours and was able to attain a 75% accuracy 
It identifies the emotions of a user and labels them into 7 categories - [angry,neutral,fear,happy,sad,surprised,neutral]

INSTRUCTIONS TO RUN -->
1. Download the files in a zip folder and open the folder in an editor(preferably vs code/pycharm).
2. run index.py and let the model bulid in the terminal till it reaches the max epochs and maximum accuracy is reached.
3. run videotester.py to test the model and verify the results.
